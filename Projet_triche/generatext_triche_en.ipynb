{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Etude code de triche, version finale (v1)\n",
        "la version 3 n'a pas marché pour plusieurs raisons. J'ai donc décidé de sauter le pas et de passer du côté *pré-trained* de la force. En plus d'être celle qui sera finalement concluante, elle me parait plus à propos par rapport au projet principal.\n",
        "\n",
        "  * **projet principal** : Je le rappelle au cas où, mais ce code dois servir à un projet collaboratif avec Asyl_himi. Tandis qu'il se farcit le côté *nouvelle*, moi je m'occupe de la partie *code*.\n",
        "  \n",
        "  * **mode opératoire** : J'ai utilisé 2 modèles pré-entrainés: *gpt-2* et *BERT*. Seul le modèle gpt-2 a été entrainé à écrire comme Balzac. L'entrainement, qui n'a pas été fait sur notebook, s'est bien passé. Malheureusement, lors de la génération de texte, il peine à faire preuve d'imagination après un point. C'est pour ça que j'utilise *BERT*! pour relancer une pièce dans la machine.\n",
        "la (V2), si elle existe, n'aura pas de *BERT*!\n"
      ],
      "metadata": {
        "id": "DWIO-zj6syuC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJVc0Dk_cQvd"
      },
      "outputs": [],
      "source": [
        "from random import randint\n",
        "from transformers import  AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
        "import tensorflow.keras as keras\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import re\n",
        "#/content/drive/MyDrive/triche"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  1.  On commence par mettre les fonctions qui vont nous servir par la suite."
      ],
      "metadata": {
        "id": "LXORyIilYE_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def script_file (adress,name,content):#script fichier\n",
        "    #adress=l'adresse dans lequel se trouvera le fichier\n",
        "    #name=nom du fichier (penser à ajouter .txt)\n",
        "    #content= le contenue.\n",
        "\n",
        "    f2=open(adress+name,\"w\",encoding=\"utf8\")\n",
        "    print(content,file=f2)\n",
        "    f2.close()"
      ],
      "metadata": {
        "id": "l6tcVeheVoUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_generator (input_text,suff_max_len=100):#generateur transformer BERT\n",
        "  #input_text= le texte qui sera en input\n",
        "  #suff_max_len= max length en plus\n",
        "\n",
        "  #---importation du modèle et des tokens\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "  model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "  #---tokenizer l'input text\n",
        "  input_ids = tokenizer(input_text, return_tensors=\"tf\").input_ids\n",
        "\n",
        "  #---générer l'output texte\n",
        "  outputs = model.generate(input_ids,\n",
        "                          max_length=len(input_ids)+suff_max_len,\n",
        "                          num_return_sequences=1,\n",
        "                          temperature=0.7,            # Contrôle la créativité\n",
        "                          top_p=0.9,                  # Active nucleus sampling\n",
        "                          top_k=50,                   # Limite aux 50 tokens les plus probable\n",
        "                          repetition_penalty=1.2 )\n",
        "\n",
        "  generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "  return generated_text\n",
        "\n"
      ],
      "metadata": {
        "id": "1wLhLIsdrV9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  2.  On continue par importer le modèle qu'on a entrainé plus tôt ainsi que les tokens associés."
      ],
      "metadata": {
        "id": "BX_ZyzWuXr7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/triche/balzac_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/triche/balzac_model_token\")"
      ],
      "metadata": {
        "id": "k4sLxXzIcgiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  3.  Et enfin on génère le texte."
      ],
      "metadata": {
        "id": "0OB32-8bh1LM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model = AutoModelForCausalLM.from_pretrained(\"./balzac_model\")\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"./balzac_model_token\")\n",
        "\n",
        "# Texte initial\n",
        "#prompt = \"In a luxurious 19th-century Parisian salon, the great Prince de Morgade welcomed his cousins\"\n",
        "#prompt = \"In a luxurious 19th-century Parisian salon,\"\n",
        "prompt=\"In a luxurious 19th-century Parisian salon, the dining\"\n",
        "current_text = prompt\n",
        "stock=[prompt]\n",
        "\n",
        "for _ in range(40):  # boucle qui permet de faire _ générations\n",
        "    #---initialisation des données d'entrée\n",
        "    print(_,\"\\n \\n\")\n",
        "    input_tokens = tokenizer(current_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    #---génération de texte\n",
        "    print(\"len input_token\",len(input_tokens[0]))\n",
        "    suff_max_len=120\n",
        "    output_tokens = model.generate(\n",
        "        input_tokens[\"input_ids\"],\n",
        "        attention_mask=input_tokens[\"attention_mask\"],\n",
        "        max_length=len(input_tokens[0])+suff_max_len,  #\n",
        "        do_sample=True,\n",
        "        temperature=0.9, #originalité\n",
        "        top_k=50,\n",
        "        top_p=0.7,\n",
        "        repetition_penalty=1.1,\n",
        "        no_repeat_ngram_size=3,  # fait pour éviter les répétitions directes\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "\n",
        "\n",
        "    print(\"len output_tokens[0]\",len(output_tokens[0]))\n",
        "    generated_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
        "    print(\"generated_text\",generated_text)\n",
        "\n",
        "    #---extraction et analyse de la partie générée (uniquement)\n",
        "    new_text = generated_text[len(current_text):].strip()\n",
        "    #---si new_text est vide, on s'aide d'un autre transformer (pas entrainé)= BERT\n",
        "    if new_text==\"\":\n",
        "\n",
        "      generated_text=bert_generator (generated_text,suff_max_len)\n",
        "\n",
        "      #generated_text=bert_generator (generated_text)\n",
        "      new_text = generated_text[len(current_text):].strip()\n",
        "      print(\"\\n\",\" ---\"*20,\"\\n\",\"new_text_bert=\", new_text,\"\\n\",\" ---\"*20,\"/n\")\n",
        "      new_text = new_text.split()[0]\n",
        "      print(\"\\n\",\"_____new new_text_bert=\", new_text,\"\\n\")\n",
        "\n",
        "    #---ajout de ce qui a été généré dans stock + current_text\n",
        "    stock.append(new_text)\n",
        "    current_text += \" \" + new_text\n",
        "    print(\"\\n\",\" ***\"*20,\"\\n\",\"current_text=\",current_text,\"\\n\",\" ***\"*20,\"/n\")\n",
        "\n",
        "    if _ %4 ==0 and _!=0:\n",
        "      stock.append(\"\\n\")#paragraphe\n",
        "      #re.split(r\"[;.]\", current_text)\n",
        "      #--on désengorge le current_text pour éviter d'atteindre le max_len.\n",
        "      if re.split(r\"[;.]\", current_text)[-1]==\"\" or re.split(r\"[;.]\", current_text)[-1]==\" \":\n",
        "        current_text = re.split(r\"[;.]\", current_text)[-2]\n",
        "      else:\n",
        "        current_text=re.split(r\"[;.]\", current_text)[-1]\n",
        "\n",
        "#---résultat final\n",
        "print(\"Texte généré complet :\")\n",
        "print(current_text)\n",
        "print(\" \".join(stock))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8RTxBgecmV1",
        "outputId": "baa4f4f7-42c1-406e-f059-bfdc1a6f9f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 \n",
            " \n",
            "\n",
            "len input_token 13\n",
            "len output_tokens[0] 21\n",
            "generated_text In a luxurious 19th-century Parisian salon, the dining room was divided into two rooms.\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text= In a luxurious 19th-century Parisian salon, the dining room was divided into two rooms. \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "1 \n",
            " \n",
            "\n",
            "len input_token 20\n",
            "len output_tokens[0] 21\n",
            "generated_text In a luxurious 19th-century Parisian salon, the dining room was divided into two rooms.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- \n",
            " new_text_bert= The first had an open kitchen with three large tables and one small table in front of it; this served as both seating for guests or to sit on while they were eating dinner at their own place (the second is reserved only by staff).\n",
            "The third floor also featured four separate bedrooms that could be shared between people who wanted more space but didn't want too much privacy from other diners: there are no windows so you can see through them without having your eyes closed when looking down onto something else's \n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- /n\n",
            "\n",
            " _____new new_text_bert= The \n",
            "\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text= In a luxurious 19th-century Parisian salon, the dining room was divided into two rooms. The \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "2 \n",
            " \n",
            "\n",
            "len input_token 21\n",
            "len output_tokens[0] 87\n",
            "generated_text In a luxurious 19th-century Parisian salon, the dining room was divided into two rooms. The first had marble windows and covered with white plaster; there were no curtains in sight of each other for three hundred francs (or twelve thousand duchesse de nucingen's), while all manner outcasts came by candlelight to enjoy themselves at one table or another--a scene that seemed natural given its surroundings.\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text= In a luxurious 19th-century Parisian salon, the dining room was divided into two rooms. The first had marble windows and covered with white plaster; there were no curtains in sight of each other for three hundred francs (or twelve thousand duchesse de nucingen's), while all manner outcasts came by candlelight to enjoy themselves at one table or another--a scene that seemed natural given its surroundings. \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "3 \n",
            " \n",
            "\n",
            "len input_token 86\n",
            "len output_tokens[0] 87\n",
            "generated_text In a luxurious 19th-century Parisian salon, the dining room was divided into two rooms. The first had marble windows and covered with white plaster; there were no curtains in sight of each other for three hundred francs (or twelve thousand duchesse de nucingen's), while all manner outcasts came by candlelight to enjoy themselves at one table or another--a scene that seemed natural given its surroundings.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- \n",
            " new_text_bert= The second floor consisted entirely on wood floors: it contained an open kitchen where guests could sit down from their chairs as they pleased without any needling them about anything else besides \n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- /n\n",
            "\n",
            " _____new new_text_bert= The \n",
            "\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text= In a luxurious 19th-century Parisian salon, the dining room was divided into two rooms. The first had marble windows and covered with white plaster; there were no curtains in sight of each other for three hundred francs (or twelve thousand duchesse de nucingen's), while all manner outcasts came by candlelight to enjoy themselves at one table or another--a scene that seemed natural given its surroundings. The \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "4 \n",
            " \n",
            "\n",
            "len input_token 87\n",
            "len output_tokens[0] 138\n",
            "generated_text In a luxurious 19th-century Parisian salon, the dining room was divided into two rooms. The first had marble windows and covered with white plaster; there were no curtains in sight of each other for three hundred francs (or twelve thousand duchesse de nucingen's), while all manner outcasts came by candlelight to enjoy themselves at one table or another--a scene that seemed natural given its surroundings. The second is decorated as if it belonged exclusively among those apartments where women are paid less than men: these furnishings served more besides their own needs on parisienne houses when they could afford them like this but only so far from luxury did mme.\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text= In a luxurious 19th-century Parisian salon, the dining room was divided into two rooms. The first had marble windows and covered with white plaster; there were no curtains in sight of each other for three hundred francs (or twelve thousand duchesse de nucingen's), while all manner outcasts came by candlelight to enjoy themselves at one table or another--a scene that seemed natural given its surroundings. The second is decorated as if it belonged exclusively among those apartments where women are paid less than men: these furnishings served more besides their own needs on parisienne houses when they could afford them like this but only so far from luxury did mme. \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "5 \n",
            " \n",
            "\n",
            "len input_token 50\n",
            "len output_tokens[0] 52\n",
            "generated_text  The second is decorated as if it belonged exclusively among those apartments where women are paid less than men: these furnishings served more besides their own needs on parisienne houses when they could afford them like this but only so far from luxury did mme.\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  The second is decorated as if it belonged exclusively among those apartments where women are paid less than men: these furnishings served more besides their own needs on parisienne houses when they could afford them like this but only so far from luxury did mme . \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "6 \n",
            " \n",
            "\n",
            "len input_token 51\n",
            "len output_tokens[0] 52\n",
            "generated_text  The second is decorated as if it belonged exclusively among those apartments where women are paid less than men: these furnishings served more besides their own needs on parisienne houses when they could afford them like this but only so far from luxury did mme .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- \n",
            " new_text_bert= The third, which was the most expensive one in all of Paris and had a very high price tag (about $1.5 million), has been painted by an artist who lives near to Mouton-en-Yvelines with his wife; he also paints some other pieces that have not yet reached market or were never intended for sale \n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- /n\n",
            "\n",
            " _____new new_text_bert= The \n",
            "\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  The second is decorated as if it belonged exclusively among those apartments where women are paid less than men: these furnishings served more besides their own needs on parisienne houses when they could afford them like this but only so far from luxury did mme . The \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "7 \n",
            " \n",
            "\n",
            "len input_token 52\n",
            "len output_tokens[0] 62\n",
            "generated_text  The second is decorated as if it belonged exclusively among those apartments where women are paid less than men: these furnishings served more besides their own needs on parisienne houses when they could afford them like this but only so far from luxury did mme . The third, which bears the title of \" \n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  The second is decorated as if it belonged exclusively among those apartments where women are paid less than men: these furnishings served more besides their own needs on parisienne houses when they could afford them like this but only so far from luxury did mme . The third, which bears the title of \" \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "8 \n",
            " \n",
            "\n",
            "len input_token 60\n",
            "len output_tokens[0] 83\n",
            "generated_text  The second is decorated as if it belonged exclusively among those apartments where women are paid less than men: these furnishings served more besides their own needs on parisienne houses when they could afford them like this but only so far from luxury did mme . The third, which bears the title of \"the delphine de la vauquer,\" was built in a hotel at  Vaudois.\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  The second is decorated as if it belonged exclusively among those apartments where women are paid less than men: these furnishings served more besides their own needs on parisienne houses when they could afford them like this but only so far from luxury did mme . The third, which bears the title of \" the delphine de la vauquer,\" was built in a hotel at  Vaudois. \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "9 \n",
            " \n",
            "\n",
            "len input_token 30\n",
            "len output_tokens[0] 32\n",
            "generated_text  The third, which bears the title of \" the delphine de la vauquer,\" was built in a hotel at  Vaudois.\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  The third, which bears the title of \" the delphine de la vauquer,\" was built in a hotel at  Vaudois . \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "10 \n",
            " \n",
            "\n",
            "len input_token 31\n",
            "len output_tokens[0] 32\n",
            "generated_text  The third, which bears the title of \" the delphine de la vauquer,\" was built in a hotel at  Vaudois .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- \n",
            " new_text_bert= It is said that it had been used by French soldiers to kill their enemies.\n",
            "The fourth and final piece on the list were two other buildings located near Paris , one for military purposes (the second being called La Ville ) and another as an exhibition hall where prisoners could be kept during wartime or when they needed help with work after war broke out between France's allies Germany and Russia. These three structures are believed not only have survived but also served \n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- /n\n",
            "\n",
            " _____new new_text_bert= It \n",
            "\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  The third, which bears the title of \" the delphine de la vauquer,\" was built in a hotel at  Vaudois . It \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "11 \n",
            " \n",
            "\n",
            "len input_token 32\n",
            "len output_tokens[0] 54\n",
            "generated_text  The third, which bears the title of \" the delphine de la vauquer,\" was built in a hotel at  Vaudois . It is not known whether it belonged to her or that she had given up its furnishings for another house.\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  The third, which bears the title of \" the delphine de la vauquer,\" was built in a hotel at  Vaudois . It is not known whether it belonged to her or that she had given up its furnishings for another house. \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "12 \n",
            " \n",
            "\n",
            "len input_token 53\n",
            "len output_tokens[0] 54\n",
            "generated_text  The third, which bears the title of \" the delphine de la vauquer,\" was built in a hotel at  Vaudois . It is not known whether it belonged to her or that she had given up its furnishings for another house.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- \n",
            " new_text_bert= The fourth and final building on this site has been named after an old French villa by Louis XIV , who lived there from 1775-1815 (see below). This one dates back about 1550s when he bought his first residence here as part 'of' France's royal family; but no records exist concerning him until 18 \n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- /n\n",
            "\n",
            " _____new new_text_bert= The \n",
            "\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  The third, which bears the title of \" the delphine de la vauquer,\" was built in a hotel at  Vaudois . It is not known whether it belonged to her or that she had given up its furnishings for another house. The \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "13 \n",
            " \n",
            "\n",
            "len input_token 1\n",
            "len output_tokens[0] 30\n",
            "generated_text  The rest of the family were at their lowest ebb, and they had to be left in a state where there was no prospect for happiness.\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  The rest of the family were at their lowest ebb, and they had to be left in a state where there was no prospect for happiness. \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "14 \n",
            " \n",
            "\n",
            "len input_token 29\n",
            "len output_tokens[0] 30\n",
            "generated_text  The rest of the family were at their lowest ebb, and they had to be left in a state where there was no prospect for happiness.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- \n",
            " new_text_bert= The next day I went out with my wife on our way home from work; she told me that her husband's mother-in law would not let us go because he wanted his daughter back as soon after marriage ended so we could have some time off before going into labour again (she said it wasn't possible). She also mentioned how much money Mr Smith made while working full time but didn't know what else about him or why this happened – which \n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- /n\n",
            "\n",
            " _____new new_text_bert= The \n",
            "\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  The rest of the family were at their lowest ebb, and they had to be left in a state where there was no prospect for happiness. The \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "15 \n",
            " \n",
            "\n",
            "len input_token 30\n",
            "len output_tokens[0] 58\n",
            "generated_text  The rest of the family were at their lowest ebb, and they had to be left in a state where there was no prospect for happiness. The old man felt that he should go back into his father's world; it seemed as if everything would turn out exactly like this now....\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  The rest of the family were at their lowest ebb, and they had to be left in a state where there was no prospect for happiness. The old man felt that he should go back into his father's world; it seemed as if everything would turn out exactly like this now.... \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "16 \n",
            " \n",
            "\n",
            "len input_token 57\n",
            "len output_tokens[0] 58\n",
            "generated_text  The rest of the family were at their lowest ebb, and they had to be left in a state where there was no prospect for happiness. The old man felt that he should go back into his father's world; it seemed as if everything would turn out exactly like this now....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- \n",
            " new_text_bert= The next day I went up with my mother on her way home from school when she heard something about an accident which happened near our house: we saw two men who looked very much alike but did not look quite so different either... They said nothing more than \"I'm sorry\" or \"You're fine.\" \n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- /n\n",
            "\n",
            " _____new new_text_bert= The \n",
            "\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  The rest of the family were at their lowest ebb, and they had to be left in a state where there was no prospect for happiness. The old man felt that he should go back into his father's world; it seemed as if everything would turn out exactly like this now.... The \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "17 \n",
            " \n",
            "\n",
            "len input_token 1\n",
            "len output_tokens[0] 44\n",
            "generated_text  The other women, with their eyes fixed on the ceiling above them and mouths open wide in amazement at her own figure as she watched a woman of twenty-four years old walk down from one side to another.\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  The other women, with their eyes fixed on the ceiling above them and mouths open wide in amazement at her own figure as she watched a woman of twenty-four years old walk down from one side to another. \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "18 \n",
            " \n",
            "\n",
            "len input_token 43\n",
            "len output_tokens[0] 44\n",
            "generated_text  The other women, with their eyes fixed on the ceiling above them and mouths open wide in amazement at her own figure as she watched a woman of twenty-four years old walk down from one side to another.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- \n",
            " new_text_bert= \"I'm so glad you're here,\" said Mrs. Bessie; \"you've been such an inspiration for me.\" She looked up into his face again before turning back towards him: he was smiling like that too—he had never seen anything quite this beautiful since I'd left home! He smiled even more when we met after dinner about two o'clock or three p \n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- /n\n",
            "\n",
            " _____new new_text_bert= \"I'm \n",
            "\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  The other women, with their eyes fixed on the ceiling above them and mouths open wide in amazement at her own figure as she watched a woman of twenty-four years old walk down from one side to another. \"I'm \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "19 \n",
            " \n",
            "\n",
            "len input_token 46\n",
            "len output_tokens[0] 50\n",
            "generated_text  The other women, with their eyes fixed on the ceiling above them and mouths open wide in amazement at her own figure as she watched a woman of twenty-four years old walk down from one side to another. \"I'm going out,\"\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  The other women, with their eyes fixed on the ceiling above them and mouths open wide in amazement at her own figure as she watched a woman of twenty-four years old walk down from one side to another. \"I'm going out,\" \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "20 \n",
            " \n",
            "\n",
            "len input_token 49\n",
            "len output_tokens[0] 64\n",
            "generated_text  The other women, with their eyes fixed on the ceiling above them and mouths open wide in amazement at her own figure as she watched a woman of twenty-four years old walk down from one side to another. \"I'm going out,\" said they all together; he was only thirty feet away by then.\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  The other women, with their eyes fixed on the ceiling above them and mouths open wide in amazement at her own figure as she watched a woman of twenty-four years old walk down from one side to another. \"I'm going out,\" said they all together; he was only thirty feet away by then. \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "21 \n",
            " \n",
            "\n",
            "len input_token 8\n",
            "len output_tokens[0] 29\n",
            "generated_text  he was only thirty feet away by then; the old man had been there for twelve months, and that meant ten years of his life.\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  he was only thirty feet away by then ; the old man had been there for twelve months, and that meant ten years of his life. \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "22 \n",
            " \n",
            "\n",
            "len input_token 28\n",
            "len output_tokens[0] 29\n",
            "generated_text  he was only thirty feet away by then ; the old man had been there for twelve months, and that meant ten years of his life.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- \n",
            " new_text_bert= He said to me : \" I have never seen a person so young as you.\"\n",
            "The next day we went out into town with him in order not to be disturbed at all; but when they came back from their journey home it seemed very strange indeed how much more difficult this adventure must become ! The first thing which struck my mind about them were two things: one is what happened on our way up through France . It seems quite certain now ,that these men \n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- /n\n",
            "\n",
            " _____new new_text_bert= He \n",
            "\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  he was only thirty feet away by then ; the old man had been there for twelve months, and that meant ten years of his life. He \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "23 \n",
            " \n",
            "\n",
            "len input_token 29\n",
            "len output_tokens[0] 68\n",
            "generated_text  he was only thirty feet away by then ; the old man had been there for twelve months, and that meant ten years of his life. He could not be out in a fortnight at any rate; it would have cost him fifty thousand francs to leave this poor widow alone with her children's happiness as soon she left them----\"\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  he was only thirty feet away by then ; the old man had been there for twelve months, and that meant ten years of his life. He could not be out in a fortnight at any rate; it would have cost him fifty thousand francs to leave this poor widow alone with her children's happiness as soon she left them----\" \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "24 \n",
            " \n",
            "\n",
            "len input_token 67\n",
            "len output_tokens[0] 68\n",
            "generated_text  he was only thirty feet away by then ; the old man had been there for twelve months, and that meant ten years of his life. He could not be out in a fortnight at any rate; it would have cost him fifty thousand francs to leave this poor widow alone with her children's happiness as soon she left them----\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- \n",
            " new_text_bert= The young woman looked up from where they were sitting on their sofa-clothes into my eyes again--and I saw nothing but tears streaming down its face like water flowing through an empty cupboard---the same thing happened when we sat together before our table next to \n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- /n\n",
            "\n",
            " _____new new_text_bert= The \n",
            "\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  he was only thirty feet away by then ; the old man had been there for twelve months, and that meant ten years of his life. He could not be out in a fortnight at any rate; it would have cost him fifty thousand francs to leave this poor widow alone with her children's happiness as soon she left them----\" The \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "25 \n",
            " \n",
            "\n",
            "len input_token 28\n",
            "len output_tokens[0] 71\n",
            "generated_text  it would have cost him fifty thousand francs to leave this poor widow alone with her children's happiness as soon she left them----\" The young man, turning back from the scene of his exploits and rastignacian conduct in an effort to clear himself for a moment that was impossible at present (as he looked round), went on: \"\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  it would have cost him fifty thousand francs to leave this poor widow alone with her children's happiness as soon she left them----\" The young man, turning back from the scene of his exploits and rastignacian conduct in an effort to clear himself for a moment that was impossible at present (as he looked round), went on: \" \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "26 \n",
            " \n",
            "\n",
            "len input_token 70\n",
            "len output_tokens[0] 71\n",
            "generated_text  it would have cost him fifty thousand francs to leave this poor widow alone with her children's happiness as soon she left them----\" The young man, turning back from the scene of his exploits and rastignacian conduct in an effort to clear himself for a moment that was impossible at present (as he looked round), went on: \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- \n",
            " new_text_bert= I am not going to be able now to live without my wife. I will go out into society.\"\n",
            "The old woman who had been so much affected by these words did nothing but look upon herself like one whose life depended entirely solely or wholly off- \n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- /n\n",
            "\n",
            " _____new new_text_bert= I \n",
            "\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  it would have cost him fifty thousand francs to leave this poor widow alone with her children's happiness as soon she left them----\" The young man, turning back from the scene of his exploits and rastignacian conduct in an effort to clear himself for a moment that was impossible at present (as he looked round), went on: \" I \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "27 \n",
            " \n",
            "\n",
            "len input_token 71\n",
            "len output_tokens[0] 92\n",
            "generated_text  it would have cost him fifty thousand francs to leave this poor widow alone with her children's happiness as soon she left them----\" The young man, turning back from the scene of his exploits and rastignacian conduct in an effort to clear himself for a moment that was impossible at present (as he looked round), went on: \" I will do my best; i am sure there are some good men out here who could be trusted.\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  it would have cost him fifty thousand francs to leave this poor widow alone with her children's happiness as soon she left them----\" The young man, turning back from the scene of his exploits and rastignacian conduct in an effort to clear himself for a moment that was impossible at present (as he looked round), went on: \" I will do my best; i am sure there are some good men out here who could be trusted. \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "28 \n",
            " \n",
            "\n",
            "len input_token 91\n",
            "len output_tokens[0] 92\n",
            "generated_text  it would have cost him fifty thousand francs to leave this poor widow alone with her children's happiness as soon she left them----\" The young man, turning back from the scene of his exploits and rastignacian conduct in an effort to clear himself for a moment that was impossible at present (as he looked round), went on: \" I will do my best; i am sure there are some good men out here who could be trusted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- \n",
            " new_text_bert= But if you want me now--I shall not go into any trouble.\"\n",
            "The old gentleman said nothing more about what had happened before or after leaving \n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- /n\n",
            "\n",
            " _____new new_text_bert= But \n",
            "\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  it would have cost him fifty thousand francs to leave this poor widow alone with her children's happiness as soon she left them----\" The young man, turning back from the scene of his exploits and rastignacian conduct in an effort to clear himself for a moment that was impossible at present (as he looked round), went on: \" I will do my best; i am sure there are some good men out here who could be trusted. But \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "29 \n",
            " \n",
            "\n",
            "len input_token 1\n",
            "len output_tokens[0] 37\n",
            "generated_text  But the vicomtesse of old, who had not been there when this affair was going on and whose name is unknown to me now that i have become acquainted with it.\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  But the vicomtesse of old, who had not been there when this affair was going on and whose name is unknown to me now that i have become acquainted with it. \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "30 \n",
            " \n",
            "\n",
            "len input_token 36\n",
            "len output_tokens[0] 37\n",
            "generated_text  But the vicomtesse of old, who had not been there when this affair was going on and whose name is unknown to me now that i have become acquainted with it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- \n",
            " new_text_bert= I am sure they were all in a state which would be very difficult for them if we could find out what happened at their place; but as soon as my father came home he said: \"I will go back.\" And so his wife went away without any trouble or difficulty from her husband's absence till she found him again after some time having gone off by himself into another country where no one knew anything about us except our \n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- /n\n",
            "\n",
            " _____new new_text_bert= I \n",
            "\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  But the vicomtesse of old, who had not been there when this affair was going on and whose name is unknown to me now that i have become acquainted with it. I \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "31 \n",
            " \n",
            "\n",
            "len input_token 37\n",
            "len output_tokens[0] 68\n",
            "generated_text  But the vicomtesse of old, who had not been there when this affair was going on and whose name is unknown to me now that i have become acquainted with it. I must say one thing about her; she has always made a terrible bargain for my happiness by making all sorts out of myself in exchange for your friendship!\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  But the vicomtesse of old, who had not been there when this affair was going on and whose name is unknown to me now that i have become acquainted with it. I must say one thing about her; she has always made a terrible bargain for my happiness by making all sorts out of myself in exchange for your friendship! \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "32 \n",
            " \n",
            "\n",
            "len input_token 67\n",
            "len output_tokens[0] 68\n",
            "generated_text  But the vicomtesse of old, who had not been there when this affair was going on and whose name is unknown to me now that i have become acquainted with it. I must say one thing about her; she has always made a terrible bargain for my happiness by making all sorts out of myself in exchange for your friendship!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- \n",
            " new_text_bert= She never gave up hope or any other kind of love at first sight but only pretended so much as an affectionate look upon you which would make no difference if we were friends again after our marriage (which may be true) because they knew how hard he could get away \n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- /n\n",
            "\n",
            " _____new new_text_bert= She \n",
            "\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  But the vicomtesse of old, who had not been there when this affair was going on and whose name is unknown to me now that i have become acquainted with it. I must say one thing about her; she has always made a terrible bargain for my happiness by making all sorts out of myself in exchange for your friendship! She \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "33 \n",
            " \n",
            "\n",
            "len input_token 24\n",
            "len output_tokens[0] 39\n",
            "generated_text  she has always made a terrible bargain for my happiness by making all sorts out of myself in exchange for your friendship! She will make no more ado about it than i have done to her.\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  she has always made a terrible bargain for my happiness by making all sorts out of myself in exchange for your friendship! She will make no more ado about it than i have done to her. \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "34 \n",
            " \n",
            "\n",
            "len input_token 38\n",
            "len output_tokens[0] 39\n",
            "generated_text  she has always made a terrible bargain for my happiness by making all sorts out of myself in exchange for your friendship! She will make no more ado about it than i have done to her.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- \n",
            " new_text_bert= I am sure that you are not too much surprised at the fact, but if this is true then we shall be able to get along well together.\"\n",
            "\"I see,\" said he; \"you must know how hard and difficult things can become when one man's life becomes another woman's business!\" He was very glad indeed with his words as they were spoken—he had been so busy lately trying to convince himself \n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- /n\n",
            "\n",
            " _____new new_text_bert= I \n",
            "\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  she has always made a terrible bargain for my happiness by making all sorts out of myself in exchange for your friendship! She will make no more ado about it than i have done to her. I \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "35 \n",
            " \n",
            "\n",
            "len input_token 39\n",
            "len output_tokens[0] 60\n",
            "generated_text  she has always made a terrible bargain for my happiness by making all sorts out of myself in exchange for your friendship! She will make no more ado about it than i have done to her. I know that you are very fond of me, and we shall never be apart; but now--\"\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  she has always made a terrible bargain for my happiness by making all sorts out of myself in exchange for your friendship! She will make no more ado about it than i have done to her. I know that you are very fond of me, and we shall never be apart; but now--\" \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "36 \n",
            " \n",
            "\n",
            "len input_token 59\n",
            "len output_tokens[0] 60\n",
            "generated_text  she has always made a terrible bargain for my happiness by making all sorts out of myself in exchange for your friendship! She will make no more ado about it than i have done to her. I know that you are very fond of me, and we shall never be apart; but now--\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- \n",
            " new_text_bert= The girl was silent as the door opened behind them when they entered into an open room with two large tables on either side which were covered with bookshelves filled with pictures from various periods before their time: \"I am sorry,\" said one woman who had been sitting at this table since morning while another sat \n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- /n\n",
            "\n",
            " _____new new_text_bert= The \n",
            "\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  she has always made a terrible bargain for my happiness by making all sorts out of myself in exchange for your friendship! She will make no more ado about it than i have done to her. I know that you are very fond of me, and we shall never be apart; but now--\" The \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "37 \n",
            " \n",
            "\n",
            "len input_token 5\n",
            "len output_tokens[0] 19\n",
            "generated_text  but now--\" The words seemed to reach his throat, and he opened them again.\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  but now--\" The words seemed to reach his throat, and he opened them again. \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "38 \n",
            " \n",
            "\n",
            "len input_token 18\n",
            "len output_tokens[0] 19\n",
            "generated_text  but now--\" The words seemed to reach his throat, and he opened them again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- \n",
            " new_text_bert= \"I'm sorry,\" said the man who had been sitting beside him with a hand on his shoulder; then they were gone from sight for some time before it was clear that there would be no more of this sort ever coming up in any future conversation between us.\"\n",
            "The old gentleman looked at me as if I might say something about my own past life or what happened when we met here last night—he did not seem very interested either way by anything which could have come out of our mouths except perhaps an idea \n",
            "  --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- /n\n",
            "\n",
            " _____new new_text_bert= \"I'm \n",
            "\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  but now--\" The words seemed to reach his throat, and he opened them again. \"I'm \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "39 \n",
            " \n",
            "\n",
            "len input_token 21\n",
            "len output_tokens[0] 43\n",
            "generated_text  but now--\" The words seemed to reach his throat, and he opened them again. \"I'm afraid my father is ill; i feel that there are things left in me which must be dealt with.\"\n",
            "\n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** \n",
            " current_text=  but now--\" The words seemed to reach his throat, and he opened them again. \"I'm afraid my father is ill; i feel that there are things left in me which must be dealt with.\" \n",
            "  *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** /n\n",
            "Texte généré complet :\n",
            " but now--\" The words seemed to reach his throat, and he opened them again. \"I'm afraid my father is ill; i feel that there are things left in me which must be dealt with.\"\n",
            "In a luxurious 19th-century Parisian salon, the dining room was divided into two rooms. The first had marble windows and covered with white plaster; there were no curtains in sight of each other for three hundred francs (or twelve thousand duchesse de nucingen's), while all manner outcasts came by candlelight to enjoy themselves at one table or another--a scene that seemed natural given its surroundings. The second is decorated as if it belonged exclusively among those apartments where women are paid less than men: these furnishings served more besides their own needs on parisienne houses when they could afford them like this but only so far from luxury did mme. \n",
            " . The third, which bears the title of \" the delphine de la vauquer,\" was built in a hotel at  Vaudois. \n",
            " . It is not known whether it belonged to her or that she had given up its furnishings for another house. The \n",
            " rest of the family were at their lowest ebb, and they had to be left in a state where there was no prospect for happiness. The old man felt that he should go back into his father's world; it seemed as if everything would turn out exactly like this now.... The \n",
            " other women, with their eyes fixed on the ceiling above them and mouths open wide in amazement at her own figure as she watched a woman of twenty-four years old walk down from one side to another. \"I'm going out,\" said they all together; he was only thirty feet away by then. \n",
            " ; the old man had been there for twelve months, and that meant ten years of his life. He could not be out in a fortnight at any rate; it would have cost him fifty thousand francs to leave this poor widow alone with her children's happiness as soon she left them----\" The \n",
            " young man, turning back from the scene of his exploits and rastignacian conduct in an effort to clear himself for a moment that was impossible at present (as he looked round), went on: \" I will do my best; i am sure there are some good men out here who could be trusted. But \n",
            " the vicomtesse of old, who had not been there when this affair was going on and whose name is unknown to me now that i have become acquainted with it. I must say one thing about her; she has always made a terrible bargain for my happiness by making all sorts out of myself in exchange for your friendship! She \n",
            " will make no more ado about it than i have done to her. I know that you are very fond of me, and we shall never be apart; but now--\" The \n",
            " words seemed to reach his throat, and he opened them again. \"I'm afraid my father is ill; i feel that there are things left in me which must be dealt with.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" \".join(stock))\n",
        "print(\"------\")\n",
        "print(re.split(r\"[;.]\", \" \".join(stock)))"
      ],
      "metadata": {
        "id": "Z-vSWHQVgCrc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42265bb1-14aa-478a-ef95-95a0162192b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a luxurious 19th-century Parisian salon, the dining room was divided into two rooms. The first had marble windows and covered with white plaster; there were no curtains in sight of each other for three hundred francs (or twelve thousand duchesse de nucingen's), while all manner outcasts came by candlelight to enjoy themselves at one table or another--a scene that seemed natural given its surroundings. The second is decorated as if it belonged exclusively among those apartments where women are paid less than men: these furnishings served more besides their own needs on parisienne houses when they could afford them like this but only so far from luxury did mme. \n",
            " . The third, which bears the title of \" the delphine de la vauquer,\" was built in a hotel at  Vaudois. \n",
            " . It is not known whether it belonged to her or that she had given up its furnishings for another house. The \n",
            " rest of the family were at their lowest ebb, and they had to be left in a state where there was no prospect for happiness. The old man felt that he should go back into his father's world; it seemed as if everything would turn out exactly like this now.... The \n",
            " other women, with their eyes fixed on the ceiling above them and mouths open wide in amazement at her own figure as she watched a woman of twenty-four years old walk down from one side to another. \"I'm going out,\" said they all together; he was only thirty feet away by then. \n",
            " ; the old man had been there for twelve months, and that meant ten years of his life. He could not be out in a fortnight at any rate; it would have cost him fifty thousand francs to leave this poor widow alone with her children's happiness as soon she left them----\" The \n",
            " young man, turning back from the scene of his exploits and rastignacian conduct in an effort to clear himself for a moment that was impossible at present (as he looked round), went on: \" I will do my best; i am sure there are some good men out here who could be trusted. But \n",
            " the vicomtesse of old, who had not been there when this affair was going on and whose name is unknown to me now that i have become acquainted with it. I must say one thing about her; she has always made a terrible bargain for my happiness by making all sorts out of myself in exchange for your friendship! She \n",
            " will make no more ado about it than i have done to her. I know that you are very fond of me, and we shall never be apart; but now--\" The \n",
            " words seemed to reach his throat, and he opened them again. \"I'm afraid my father is ill; i feel that there are things left in me which must be dealt with.\"\n",
            "------\n",
            "['In a luxurious 19th-century Parisian salon, the dining room was divided into two rooms', ' The first had marble windows and covered with white plaster', \" there were no curtains in sight of each other for three hundred francs (or twelve thousand duchesse de nucingen's), while all manner outcasts came by candlelight to enjoy themselves at one table or another--a scene that seemed natural given its surroundings\", ' The second is decorated as if it belonged exclusively among those apartments where women are paid less than men: these furnishings served more besides their own needs on parisienne houses when they could afford them like this but only so far from luxury did mme', ' \\n ', ' The third, which bears the title of \" the delphine de la vauquer,\" was built in a hotel at \\xa0Vaudois', ' \\n ', ' It is not known whether it belonged to her or that she had given up its furnishings for another house', ' The \\n rest of the family were at their lowest ebb, and they had to be left in a state where there was no prospect for happiness', \" The old man felt that he should go back into his father's world\", ' it seemed as if everything would turn out exactly like this now', '', '', '', ' The \\n other women, with their eyes fixed on the ceiling above them and mouths open wide in amazement at her own figure as she watched a woman of twenty-four years old walk down from one side to another', ' \"I\\'m going out,\" said they all together', ' he was only thirty feet away by then', ' \\n ', ' the old man had been there for twelve months, and that meant ten years of his life', ' He could not be out in a fortnight at any rate', ' it would have cost him fifty thousand francs to leave this poor widow alone with her children\\'s happiness as soon she left them----\" The \\n young man, turning back from the scene of his exploits and rastignacian conduct in an effort to clear himself for a moment that was impossible at present (as he looked round), went on: \" I will do my best', ' i am sure there are some good men out here who could be trusted', ' But \\n the vicomtesse of old, who had not been there when this affair was going on and whose name is unknown to me now that i have become acquainted with it', ' I must say one thing about her', ' she has always made a terrible bargain for my happiness by making all sorts out of myself in exchange for your friendship! She \\n will make no more ado about it than i have done to her', ' I know that you are very fond of me, and we shall never be apart', ' but now--\" The \\n words seemed to reach his throat, and he opened them again', ' \"I\\'m afraid my father is ill', ' i feel that there are things left in me which must be dealt with', '\"']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  4.  J'exporte le texte"
      ],
      "metadata": {
        "id": "MBGiHI0PiIgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_file (\"/content/drive/MyDrive/triche/\",\"generated_text.txt\",\" \".join(stock))"
      ],
      "metadata": {
        "id": "yG_MEsweiMVC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8fa314e-6798-40b7-e825-e5b2c3c43185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'script_file' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8c2ed4d3fca8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscript_file\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/triche/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"generated_text.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'script_file' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Et voilà. Il ne me resterait qu'à traduire en français.\n",
        "Ce code sera utilisé par *Asyl_himi* pour sa nouvelle.\n",
        "\n",
        "\n",
        "<center> <b>Post_face </b> </center>\n",
        "J'ai beaucoup appris à travers ce projet, qui a été à la fois des hauts, mais surtout des bas. J'ai évidemment appris énormément, dû enchainer les trouvailles pour passer entre les mailles du filet du piège. De mon côté, je ne pense pas m'arrêter là. à vrai dire, je suis assez frustré par les versions loupés. Il y a sans-doute des erreurs bidons qui expliquent mes résultats pas ouf."
      ],
      "metadata": {
        "id": "olrxaKL2inF6"
      }
    }
  ]
}